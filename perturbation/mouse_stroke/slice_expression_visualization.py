#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Slice Expression Visualization

This script visualizes gene expression from saved expression CSV files or raw h5ad files.
Designed to work with:
  1. expression_step*.csv files generated by perturbation experiments (mode=perturbation)
  2. raw processed.h5ad files for visualizing original slice expression (mode=raw)

Features:
- Visualizes entire slice expression for specific genes
- Custom colormap: F47F1E (orange, high) -> light gray -> 9368AB (purple, low)
- Highlights perturbed spots only at step 0 (perturbation mode only):
  - For patch mode: draws outline around the perturbed patch
  - For random mode: draws thin red circles around each perturbed spot
- Supports multiple steps, genes, and settings

Usage (perturbation mode):
    python slice_expression_visualization.py \
        --mode perturbation \
        --expr_dir /path/to/expression \
        --manifest_path /path/to/perturb_manifest.json \
        --genes "Cacng3,Gfap" \
        --steps "0,1,10" \
        --cache_dir /path/to/cache \
        --dataset_name Sham1-1 \
        --out_dir /path/to/output

Usage (raw mode - visualize original slice):
    python slice_expression_visualization.py \
        --mode raw \
        --genes "Cacng3,Gfap" \
        --cache_dir /path/to/cache \
        --dataset_name Sham1-1 \
        --out_dir /path/to/output
"""

from __future__ import annotations

import argparse
import json
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Set

import numpy as np
import pandas as pd

# Set non-interactive backend before importing pyplot (for headless servers)
import matplotlib
matplotlib.use('Agg')

import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
from matplotlib.colors import LinearSegmentedColormap, Normalize
from matplotlib.collections import PathCollection
from scipy.spatial import ConvexHull


# ==============================================================================
# Custom colormap: Purple (#9368AB, low) -> Light Gray -> Orange (#F47F1E, high)
# ==============================================================================

def create_custom_colormap():
    """
    Create a custom colormap from purple (low) through light gray to orange (high).
    Low expression: #9368AB (purple)
    Mid expression: #D0D0D0 (light gray)
    High expression: #F47F1E (orange)
    """
    # Parse hex colors to RGB
    purple = (0x93 / 255, 0x68 / 255, 0xAB / 255)   # #9368AB
    light_gray = (0xD0 / 255, 0xD0 / 255, 0xD0 / 255)  # #D0D0D0
    orange = (0xF4 / 255, 0x7F / 255, 0x1E / 255)   # #F47F1E
    
    cmap = LinearSegmentedColormap.from_list(
        "custom_purple_gray_orange", 
        [purple, light_gray, orange], 
        N=256
    )
    return cmap


# Global custom colormap
CUSTOM_CMAP = create_custom_colormap()


# ==============================================================================
# Utility functions
# ==============================================================================

def _load_json(path: Path) -> Dict:
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def _get_dataset_start_idx(cache_dir: Path, dataset_name: str) -> int:
    """Get the global index offset for a dataset in the cache."""
    meta = _load_json(cache_dir / "metadata.json")
    datasets = meta.get("datasets", [])
    dataset_idx = None
    for i, ds in enumerate(datasets):
        if ds.get("name") == dataset_name:
            dataset_idx = i
            break
    if dataset_idx is None:
        dataset_idx = 0
    for info in meta.get("dataset_indices", []):
        if info.get("dataset_idx") == dataset_idx:
            return int(info.get("start_idx", 0))
    return 0


def load_spatial_coords(
    cache_dir: Path,
    dataset_name: str,
) -> Tuple[Dict[str, Tuple[float, float]], Dict[str, int]]:
    """
    Load spatial coordinates for ALL spots in the slice.
    Returns ({barcode: (x, y)}, {barcode: global_idx}).
    """
    import anndata as ad
    
    start_idx = _get_dataset_start_idx(cache_dir, dataset_name)
    proc_path = cache_dir / dataset_name / "processed.h5ad"
    
    if not proc_path.exists():
        raise FileNotFoundError(f"Processed h5ad not found: {proc_path}")
    
    proc = ad.read_h5ad(str(proc_path), backed="r")
    
    coords = {}
    barcode_to_gidx = {}
    for local in range(proc.n_obs):
        barcode = proc.obs_names[local]
        gidx = int(start_idx) + local
        xy = proc.obsm["spatial"][local]
        coords[barcode] = (float(xy[0]), float(xy[1]))
        barcode_to_gidx[barcode] = gidx
    
    return coords, barcode_to_gidx


def load_raw_expression_from_h5ad(
    cache_dir: Path,
    dataset_name: str,
    gene_name: str,
    coords: Dict[str, Tuple[float, float]],
    use_layer: str = "X_log1p",
) -> Dict[str, float]:
    """
    Load expression values for a specific gene directly from processed.h5ad.
    Used for 'raw' mode to visualize original slice expression.
    
    Args:
        cache_dir: Cache directory path
        dataset_name: Dataset name
        gene_name: Gene name to extract
        coords: Coordinate dictionary
        use_layer: Which layer to use for expression values.
                   Options: "X_log1p" (log-normalized, default), 
                            "X_normed" (normalized), 
                            "counts" (raw counts),
                            "X" (main matrix, usually counts)
    
    Returns {barcode: expression_value}.
    """
    import anndata as ad
    import scipy.sparse as sp
    
    proc_path = cache_dir / dataset_name / "processed.h5ad"
    
    if not proc_path.exists():
        raise FileNotFoundError(f"Processed h5ad not found: {proc_path}")
    
    proc = ad.read_h5ad(str(proc_path))
    
    # Find the gene column (case-insensitive matching)
    gene_names_lower = {g.lower(): g for g in proc.var_names}
    gene_lower = gene_name.lower()
    
    if gene_lower not in gene_names_lower:
        available = list(proc.var_names[:10])
        raise ValueError(
            f"Gene '{gene_name}' not found in h5ad. "
            f"Available genes (first 10): {available}"
        )
    
    actual_gene = gene_names_lower[gene_lower]
    gene_idx = list(proc.var_names).index(actual_gene)
    
    # Extract expression values from the specified layer
    if use_layer == "X" or use_layer is None:
        X = proc.X
    elif use_layer in proc.layers:
        X = proc.layers[use_layer]
    else:
        # Fallback: try common layer names
        if "X_log1p" in proc.layers:
            print(f"  [WARN] Layer '{use_layer}' not found, using 'X_log1p'")
            X = proc.layers["X_log1p"]
        elif "X_normed" in proc.layers:
            print(f"  [WARN] Layer '{use_layer}' not found, using 'X_normed'")
            X = proc.layers["X_normed"]
        else:
            print(f"  [WARN] Layer '{use_layer}' not found, using main matrix 'X'")
            X = proc.X
    
    if sp.issparse(X):
        expr_vals = np.asarray(X[:, gene_idx].todense()).flatten()
    else:
        expr_vals = np.asarray(X[:, gene_idx]).flatten()
    
    # Map barcode to expression
    result = {}
    for i, barcode in enumerate(proc.obs_names):
        if barcode in coords:
            result[barcode] = float(expr_vals[i])
    
    return result


def load_expression_csv(csv_path: Path) -> pd.DataFrame:
    """
    Load expression CSV file.
    Returns DataFrame with barcodes as index and gene names as columns.
    """
    df = pd.read_csv(csv_path, index_col=0)
    return df


def get_gene_expression(
    df: pd.DataFrame, 
    gene_name: str, 
    coords: Dict[str, Tuple[float, float]]
) -> Dict[str, float]:
    """
    Extract expression values for a specific gene.
    Returns {barcode: expression_value}.
    """
    # Handle case-insensitive gene name matching
    gene_cols = {col.lower(): col for col in df.columns}
    gene_lower = gene_name.lower()
    
    if gene_lower not in gene_cols:
        available = list(df.columns[:10])
        raise ValueError(
            f"Gene '{gene_name}' not found in expression data. "
            f"Available genes (first 10): {available}"
        )
    
    actual_col = gene_cols[gene_lower]
    expr_series = df[actual_col]
    
    # Only return expression for spots that have coordinates
    result = {}
    for barcode in coords.keys():
        if barcode in expr_series.index:
            result[barcode] = float(expr_series[barcode])
    
    return result


# ==============================================================================
# Visualization functions
# ==============================================================================

def plot_spatial_heatmap(
    coords: Dict[str, Tuple[float, float]],
    expr_values: Dict[str, float],
    perturbed_barcodes: Optional[Set[str]],
    perturb_mode: str,
    gene_name: str,
    step: int,
    out_path: Path,
    vmin: Optional[float] = None,
    vmax: Optional[float] = None,
    spot_size: float = 20,
    figsize: Tuple[float, float] = (8, 8),
    highlight_perturbed: bool = True,
    gray_non_perturbed: bool = False,
    title: Optional[str] = None,
):
    """
    Create and save a spatial heatmap for gene expression.
    
    Args:
        coords: {barcode: (x, y)} spatial coordinates
        expr_values: {barcode: expression} gene expression values
        perturbed_barcodes: set of barcodes that were perturbed
        perturb_mode: "patch" or "random" - determines how perturbed spots are highlighted
        gene_name: name of the gene being visualized
        step: perturbation step (0 for initial perturbation)
        out_path: output file path
        vmin, vmax: color scale limits
        spot_size: size of scatter points
        figsize: figure size
        highlight_perturbed: whether to highlight perturbed spots (only for step 0)
        gray_non_perturbed: if True, at step 0 only perturbed spots are colored, 
                           others are gray, and a red bounding box is drawn
        title: custom title (optional)
    """
    fig, ax = plt.subplots(figsize=figsize)
    
    # Get values for color scaling (only from perturbed spots if gray_non_perturbed)
    if gray_non_perturbed and step == 0 and perturbed_barcodes:
        vals = [expr_values.get(b, 0.0) for b in perturbed_barcodes if b in coords]
    else:
        vals = [expr_values.get(b, 0.0) for b in coords.keys()]
    
    if vmin is None:
        vmin = np.nanpercentile(vals, 1) if vals else 0
    if vmax is None:
        vmax = np.nanpercentile(vals, 99) if vals else 1
    
    norm = Normalize(vmin=vmin, vmax=vmax)
    
    # Prepare data for plotting
    barcodes = list(coords.keys())
    
    # Check if we should use gray_non_perturbed mode
    use_gray_mode = gray_non_perturbed and step == 0 and perturbed_barcodes
    
    if use_gray_mode:
        # ================================================================
        # Gray mode: non-perturbed spots are gray, only perturbed are colored
        # ================================================================
        
        # Separate perturbed and non-perturbed spots
        non_pert_barcodes = [b for b in barcodes if b not in perturbed_barcodes]
        pert_barcodes = [b for b in barcodes if b in perturbed_barcodes]
        
        # Plot non-perturbed spots in gray
        if non_pert_barcodes:
            non_pert_xs = [coords[b][0] for b in non_pert_barcodes]
            non_pert_ys = [coords[b][1] for b in non_pert_barcodes]
            ax.scatter(
                non_pert_xs, non_pert_ys,
                c='#C0C0C0',  # Light gray
                s=spot_size, edgecolors="none", alpha=0.6, zorder=1,
            )
        
        # Plot perturbed spots with colormap
        if pert_barcodes:
            pert_xs = [coords[b][0] for b in pert_barcodes]
            pert_ys = [coords[b][1] for b in pert_barcodes]
            pert_colors = [expr_values.get(b, 0.0) for b in pert_barcodes]
            
            scatter = ax.scatter(
                pert_xs, pert_ys,
                c=pert_colors, cmap=CUSTOM_CMAP, norm=norm,
                s=spot_size, edgecolors="none", alpha=0.9, zorder=2,
            )
            
            # Draw red bounding box around perturbed region
            pert_xs_arr = np.array(pert_xs)
            pert_ys_arr = np.array(pert_ys)
            
            # Add padding for the bounding box
            padding = spot_size * 0.15  # Padding in data units
            x_min, x_max = pert_xs_arr.min() - padding, pert_xs_arr.max() + padding
            y_min, y_max = pert_ys_arr.min() - padding, pert_ys_arr.max() + padding
            
            # Draw rectangle
            rect = mpatches.Rectangle(
                (x_min, y_min), 
                x_max - x_min, 
                y_max - y_min,
                linewidth=2.5, 
                edgecolor='red', 
                facecolor='none',
                zorder=4
            )
            ax.add_patch(rect)
        else:
            # No perturbed spots - create a dummy scatter for colorbar
            scatter = ax.scatter([], [], c=[], cmap=CUSTOM_CMAP, norm=norm)
        
        # Legend for gray mode
        legend_label = "Perturbed Region"
        legend_marker = mpatches.Patch(
            facecolor='none', edgecolor='red', linewidth=2, label=legend_label
        )
        #ax.legend(handles=[legend_marker], loc='lower center', fontsize=9)
        
    else:
        # ================================================================
        # Normal mode: all spots colored, optional highlight for perturbed
        # ================================================================
        xs = [coords[b][0] for b in barcodes]
        ys = [coords[b][1] for b in barcodes]
        colors = [expr_values.get(b, 0.0) for b in barcodes]
        
        # Plot all spots
        scatter = ax.scatter(
            xs, ys,
            c=colors, cmap=CUSTOM_CMAP, norm=norm,
            s=spot_size, edgecolors="none", alpha=0.9, zorder=2,
        )
        
        # Highlight perturbed spots only at step 0
        should_highlight = highlight_perturbed and step == 0 and perturbed_barcodes
        
        if should_highlight:
            pert_xs = [coords[b][0] for b in perturbed_barcodes if b in coords]
            pert_ys = [coords[b][1] for b in perturbed_barcodes if b in coords]
            pert_colors = [expr_values.get(b, 0.0) for b in perturbed_barcodes if b in coords]
            
            if perturb_mode == "patch":
                # Draw convex hull around the perturbed patch
                if len(pert_xs) >= 3:
                    points = np.column_stack([pert_xs, pert_ys])
                    try:
                        hull = ConvexHull(points)
                        hull_points = points[hull.vertices]
                        # Close the polygon
                        hull_points = np.vstack([hull_points, hull_points[0]])
                        ax.plot(
                            hull_points[:, 0], hull_points[:, 1],
                            color='red', linewidth=2.5, linestyle='-', zorder=4
                        )
                    except Exception:
                        # Fallback: just draw circles if hull fails
                        ax.scatter(
                            pert_xs, pert_ys,
                            c=pert_colors, cmap=CUSTOM_CMAP, norm=norm,
                            s=spot_size * 1.2, edgecolors='red', linewidths=1.5, 
                            alpha=0.95, zorder=3
                        )
            else:
                # Random mode: thin red circles around each perturbed spot
                ax.scatter(
                    pert_xs, pert_ys,
                    c=pert_colors, cmap=CUSTOM_CMAP, norm=norm,
                    s=spot_size * 1.2, edgecolors='red', linewidths=1.0, 
                    alpha=0.95, zorder=3
                )
            
            # Add legend for highlighted spots
            if perturb_mode == "patch":
                legend_label = "Perturbed Patch"
                legend_marker = mpatches.Patch(
                    facecolor='none', edgecolor='red', linewidth=2, label=legend_label
                )
            else:
                legend_label = "Perturbed Spots"
                legend_marker = plt.Line2D(
                    [0], [0], marker='o', color='w', markerfacecolor='gray',
                    markeredgecolor='red', markersize=8, label=legend_label
                )
            ax.legend(handles=[legend_marker], loc='upper right', fontsize=9)
    
    # Set title
    if title is None:
        step_label = f"Step {step}" if step > 0 else "Pert0 (Initial)"
        title = f"{gene_name} - {step_label}"
    ax.set_title(title, fontsize=12, fontweight="bold")
    
    # Axis settings
    ax.set_aspect("equal")
    ax.set_xlabel("X", fontsize=10)
    ax.set_ylabel("Y", fontsize=10)
    ax.invert_yaxis()
    
    # Remove axis for cleaner look
    ax.axis('off')
    
    # Colorbar
    cbar = plt.colorbar(scatter, ax=ax, shrink=0.6, pad=0.02)
    cbar.set_label("Expression", fontsize=10)
    
    plt.tight_layout()
    plt.savefig(out_path, dpi=150, bbox_inches="tight", facecolor='white')
    plt.close(fig)
    print(f"[OK] Saved: {out_path}")
    
    return vmin, vmax


# ==============================================================================
# Main pipeline
# ==============================================================================

def main():
    ap = argparse.ArgumentParser(
        description="Slice Expression Visualization V2",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    
    # Mode selection
    ap.add_argument("--mode", type=str, default="perturbation", 
                    choices=["perturbation", "raw"],
                    help="Visualization mode: 'perturbation' for CSV files, 'raw' for h5ad")
    
    # Input paths (perturbation mode)
    ap.add_argument("--expr_dir", type=str, default=None,
                    help="Directory containing expression_step*.csv files (perturbation mode)")
    ap.add_argument("--manifest_path", type=str, default=None,
                    help="Path to perturb_manifest.json for perturbation info (perturbation mode)")
    
    # Common input paths
    ap.add_argument("--cache_dir", type=str, required=True,
                    help="Cache directory containing processed.h5ad for spatial coords")
    ap.add_argument("--dataset_name", type=str, default="Sham1-1",
                    help="Dataset name in the cache")
    
    # Gene and step selection
    ap.add_argument("--genes", type=str, required=True,
                    help="Comma-separated list of gene names to visualize")
    ap.add_argument("--steps", type=str, default="0,1,10",
                    help="Comma-separated list of steps to visualize (perturbation mode only)")
    
    # Visualization options
    ap.add_argument("--spot_size", type=float, default=80,
                    help="Size of scatter points")
    ap.add_argument("--figsize", type=str, default="8,8",
                    help="Figure size as 'width,height'")
    ap.add_argument("--vmin", type=float, default=None,
                    help="Minimum value for color scale (auto if not set)")
    ap.add_argument("--vmax", type=float, default=None,
                    help="Maximum value for color scale (auto if not set)")
    ap.add_argument("--auto_scale_per_gene", action="store_true",
                    help="Compute vmin/vmax separately for each gene")
    ap.add_argument("--auto_scale_per_step", action="store_true",
                    help="Compute vmin/vmax separately for each step (perturbation mode only)")
    ap.add_argument("--gray_non_perturbed", action="store_true",
                    help="At step 0, only color perturbed spots, show others in gray, "
                         "and draw a red bounding box around the perturbed region")
    ap.add_argument("--expr_layer", type=str, default="X_log1p",
                    help="Expression layer to use for raw mode: 'X_log1p' (log-normalized, default), "
                         "'X_normed', 'counts', or 'X'")
    
    # Output
    ap.add_argument("--out_dir", type=str, required=True,
                    help="Output directory for figures")
    
    args = ap.parse_args()
    
    # Parse common arguments
    cache_dir = Path(args.cache_dir)
    out_dir = Path(args.out_dir)
    out_dir.mkdir(parents=True, exist_ok=True)
    
    genes = [g.strip() for g in args.genes.split(",") if g.strip()]
    figsize = tuple(float(x) for x in args.figsize.split(","))
    
    print(f"[INFO] Mode: {args.mode}")
    print(f"[INFO] Cache directory: {cache_dir}")
    print(f"[INFO] Dataset name: {args.dataset_name}")
    print(f"[INFO] Genes to visualize: {genes}")
    print(f"[INFO] Output directory: {out_dir}")
    
    # Load spatial coordinates
    print("[INFO] Loading spatial coordinates...")
    coords, barcode_to_gidx = load_spatial_coords(cache_dir, args.dataset_name)
    print(f"[INFO] Loaded coordinates for {len(coords)} spots")
    
    if args.mode == "raw":
        # ====================================================================
        # RAW MODE: Visualize original expression from h5ad
        # ====================================================================
        print("[INFO] Raw mode: visualizing original slice expression")
        print(f"[INFO] Using expression layer: {args.expr_layer}")
        
        for gene_name in genes:
            print(f"\n[GENE] Processing: {gene_name}")
            
            try:
                expr_values = load_raw_expression_from_h5ad(
                    cache_dir, args.dataset_name, gene_name, coords,
                    use_layer=args.expr_layer
                )
                print(f"  [INFO] Loaded expression for {len(expr_values)} spots")
            except ValueError as e:
                print(f"  [ERROR] {e}")
                continue
            
            # Compute vmin/vmax
            all_vals = list(expr_values.values())
            if args.vmin is not None:
                vmin = args.vmin
            else:
                vmin = np.nanpercentile(all_vals, 1) if all_vals else 0
            
            if args.vmax is not None:
                vmax = args.vmax
            else:
                vmax = np.nanpercentile(all_vals, 99) if all_vals else 1
            
            print(f"  [INFO] Color scale: vmin={vmin:.4f}, vmax={vmax:.4f}")
            
            # Output filename for raw mode
            out_path = out_dir / f"{gene_name}_raw.png"
            
            plot_spatial_heatmap(
                coords=coords,
                expr_values=expr_values,
                perturbed_barcodes=None,  # No perturbation in raw mode
                perturb_mode="random",
                gene_name=gene_name,
                step=-1,  # Special step for raw mode (no highlight)
                out_path=out_path,
                vmin=vmin,
                vmax=vmax,
                spot_size=args.spot_size,
                figsize=figsize,
                highlight_perturbed=False,
                title=f"{gene_name} - {args.dataset_name} (Raw)",
            )
        
        print(f"\n[DONE] All visualizations saved to: {out_dir}")
        return
    
    # ====================================================================
    # PERTURBATION MODE: Visualize expression from CSV files
    # ====================================================================
    
    # Validate required arguments for perturbation mode
    if not args.expr_dir:
        raise ValueError("--expr_dir is required for perturbation mode")
    if not args.manifest_path:
        raise ValueError("--manifest_path is required for perturbation mode")
    
    expr_dir = Path(args.expr_dir)
    manifest_path = Path(args.manifest_path)
    steps = [int(s.strip()) for s in args.steps.split(",")]
    
    print(f"[INFO] Expression directory: {expr_dir}")
    print(f"[INFO] Manifest path: {manifest_path}")
    print(f"[INFO] Steps to visualize: {steps}")
    
    # Load perturbation manifest
    if not manifest_path.exists():
        raise FileNotFoundError(f"Manifest not found: {manifest_path}")
    
    manifest = _load_json(manifest_path)
    perturb_mode = manifest.get("perturb_mode", "random")
    selected_barcodes = set(manifest.get("selected_barcodes", []))
    
    print(f"[INFO] Perturbation mode: {perturb_mode}")
    print(f"[INFO] Number of perturbed spots: {len(selected_barcodes)}")
    
    # Process each gene
    for gene_name in genes:
        print(f"\n[GENE] Processing: {gene_name}")
        
        # Collect expression data across all steps for consistent color scaling
        all_expr_data = {}
        for step in steps:
            csv_path = expr_dir / f"expression_step{step}.csv"
            if not csv_path.exists():
                print(f"  [WARN] Expression file not found: {csv_path}, skipping step {step}")
                continue
            
            df = load_expression_csv(csv_path)
            try:
                expr_values = get_gene_expression(df, gene_name, coords)
                all_expr_data[step] = expr_values
                print(f"  [INFO] Loaded step {step}: {len(expr_values)} spots")
            except ValueError as e:
                print(f"  [ERROR] {e}")
                break
        
        if not all_expr_data:
            print(f"  [SKIP] No valid expression data for gene {gene_name}")
            continue
        
        # Compute global vmin/vmax for this gene (unless per-step scaling)
        if not args.auto_scale_per_step:
            all_vals = []
            for expr_values in all_expr_data.values():
                all_vals.extend(expr_values.values())
            
            if args.vmin is not None:
                global_vmin = args.vmin
            else:
                global_vmin = np.nanpercentile(all_vals, 1) if all_vals else 0
            
            if args.vmax is not None:
                global_vmax = args.vmax
            else:
                global_vmax = np.nanpercentile(all_vals, 99) if all_vals else 1
            
            print(f"  [INFO] Color scale: vmin={global_vmin:.4f}, vmax={global_vmax:.4f}")
        else:
            global_vmin, global_vmax = None, None
        
        # Generate visualization for each step
        for step, expr_values in all_expr_data.items():
            out_path = out_dir / f"{gene_name}_step{step}.png"
            
            # Determine color scale for this step
            if args.auto_scale_per_step:
                step_vmin = args.vmin
                step_vmax = args.vmax
            else:
                step_vmin = global_vmin
                step_vmax = global_vmax
            
            plot_spatial_heatmap(
                coords=coords,
                expr_values=expr_values,
                perturbed_barcodes=selected_barcodes,
                perturb_mode=perturb_mode,
                gene_name=gene_name,
                step=step,
                out_path=out_path,
                vmin=step_vmin,
                vmax=step_vmax,
                spot_size=args.spot_size,
                figsize=figsize,
                highlight_perturbed=True,
                gray_non_perturbed=args.gray_non_perturbed,
            )
    
    print(f"\n[DONE] All visualizations saved to: {out_dir}")


if __name__ == "__main__":
    main()
